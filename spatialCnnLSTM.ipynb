{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spatialCnnLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48OGSAxVeu75",
        "outputId": "8441e2d6-6e29-491b-df35-5e3a54de9b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import os\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/MyDrive/'\n",
        "print(os.getcwd())\n",
        "!rm -r /content/Dataset\n",
        "!mkdir /content/Dataset\n",
        "!cp project_data.zip /content/Dataset/\n",
        "!unzip /content/Dataset/project_data.zip -d /content/Dataset/\n",
        "!rm -r /content/Dataset/project_data.zip\n",
        "!rm -r /content/Dataset/__MACOSX/"
      ],
      "metadata": {
        "id": "FmP7lkVNe607",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe0386aa-9064-4abe-ce97-835f2e17bd27"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n",
            "/content/gdrive/MyDrive\n",
            "rm: cannot remove '/content/Dataset': No such file or directory\n",
            "Archive:  /content/Dataset/project_data.zip\n",
            "   creating: /content/Dataset/project/\n",
            "  inflating: /content/Dataset/project/EEG_loading.ipynb  \n",
            "   creating: /content/Dataset/__MACOSX/\n",
            "   creating: /content/Dataset/__MACOSX/project/\n",
            "  inflating: /content/Dataset/__MACOSX/project/._EEG_loading.ipynb  \n",
            "  inflating: /content/Dataset/project/X_train_valid.npy  \n",
            "  inflating: /content/Dataset/__MACOSX/project/._X_train_valid.npy  \n",
            "  inflating: /content/Dataset/project/.DS_Store  \n",
            "  inflating: /content/Dataset/__MACOSX/project/._.DS_Store  \n",
            "  inflating: /content/Dataset/project/person_train_valid.npy  \n",
            "  inflating: /content/Dataset/__MACOSX/project/._person_train_valid.npy  \n",
            "  inflating: /content/Dataset/project/y_train_valid.npy  \n",
            "  inflating: /content/Dataset/__MACOSX/project/._y_train_valid.npy  \n",
            "  inflating: /content/Dataset/project/y_test.npy  \n",
            "  inflating: /content/Dataset/__MACOSX/project/._y_test.npy  \n",
            "  inflating: /content/Dataset/project/X_test.npy  \n",
            "  inflating: /content/Dataset/__MACOSX/project/._X_test.npy  \n",
            "   creating: /content/Dataset/project/.ipynb_checkpoints/\n",
            "  inflating: /content/Dataset/project/.ipynb_checkpoints/EEG_loading-checkpoint.ipynb  \n",
            "   creating: /content/Dataset/__MACOSX/project/.ipynb_checkpoints/\n",
            "  inflating: /content/Dataset/__MACOSX/project/.ipynb_checkpoints/._EEG_loading-checkpoint.ipynb  \n",
            "  inflating: /content/Dataset/__MACOSX/project/._.ipynb_checkpoints  \n",
            "  inflating: /content/Dataset/project/person_test.npy  \n",
            "  inflating: /content/Dataset/__MACOSX/project/._person_test.npy  \n",
            "  inflating: /content/Dataset/__MACOSX/._project  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import interpolation\n",
        "from numpy.lib.function_base import interp\n",
        "from PIL.Image import fromarray\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class DatasetEEG(object):\n",
        "    \"\"\"\n",
        "    Class for initial part of data loading , like converting labels in range 0-3\n",
        "    Also has utility functions to return X,y examples to wrt to a specific person\n",
        "    Splitting train data into train and validation\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def make_labels(self,y_train_valid):\n",
        "        \"\"\"\n",
        "        Takes in ylabels in the range in 769 returns ylabels in range 0-3\n",
        "        \"\"\"\n",
        "        y_train_valid=y_train_valid-769\n",
        "        \n",
        "        return y_train_valid\n",
        "    \n",
        "    def train_valid_split(self,X_train_valid,y_train_valid,person_train_valid,valsplit=0.2):\n",
        "        \"\"\"\n",
        "        Function to split the given train_valid combination into training and validation in a 20% 80% split\n",
        "        Input X_train_valid, y_train_valid, person_train_valid\n",
        "        Output X_train, X_valid, y_train, y_valid, person_train, person_valid\n",
        "        \"\"\"\n",
        "        full_size=X_train_valid.shape[0]\n",
        "        val_idxs=np.random.choice(int(full_size), int(valsplit*full_size),replace=False)\n",
        "        tr_idxs = np.array(list(set(range(full_size)).difference(set(val_idxs))))\n",
        "        X_train=X_train_valid[tr_idxs]\n",
        "        y_train=y_train_valid[tr_idxs]\n",
        "        X_valid=X_train_valid[val_idxs]\n",
        "        y_valid=y_train_valid[val_idxs]\n",
        "        person_train=person_train_valid[tr_idxs]\n",
        "        person_valid=person_train_valid[val_idxs]\n",
        "        return X_train,X_valid,y_train,y_valid,person_train,person_valid\n",
        "    \n",
        "\n",
        "    def make_subject_arr(X,y,person_array,person=0):\n",
        "        \"\"\"\n",
        "        Given a train and label arrays just return train and label arrays based on the person\n",
        "        Input X,y, person_array,person\n",
        "        Output X,y corresponding to that particular person\n",
        "        \"\"\"\n",
        "        pers_idx=np.argwhere(person_array.flatten()==person)\n",
        "        X_person=X[pers_idx]\n",
        "        y_person=y[pers_idx]\n",
        "        return X_person,y_person   \n",
        "    \n",
        "    def make_task_arr(self,X,y,task=0):\n",
        "        \"\"\"\n",
        "        Given a train and label arrays just return train and label arrays based on the one of the 4 tasks\n",
        "        Input X,y, task [ 0-3]\n",
        "        Output X,y corresponding to that particular task\n",
        "        \"\"\"\n",
        "        task_idx=np.argwhere(y.flatten()==task)\n",
        "        X_task=X[task_idx]\n",
        "        y_task=y[task_idx]\n",
        "        return X_task,y_task\n",
        "    \n",
        "    def get_spatial_eeg_location(self):\n",
        "        \"\"\"\n",
        "        Return the spatial layout of the sensors \n",
        "        for interpreting them as images\n",
        "        \n",
        "        \"\"\"\n",
        "        mapping =  [[ 1, 1, 0, 0, 0, 5, 5],\n",
        "                    [ 1, 2, 2, 3, 4, 4, 5],\n",
        "                    [ 6, 7, 8, 9,10,11,12],\n",
        "                    [13,13,14,15,16,17,17],\n",
        "                    [13,18,18,19,20,20,17],\n",
        "                    [18,18,21,21,21,20,20]]\n",
        "        return mapping\n",
        "    def visualize_heatmap(self,X,y,per_arr, task=None):\n",
        "        \"\"\"\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X_arr : An array of shape N, 22, 1000 (22 EEG Chhanels , 1000 time bins)\n",
        "            DESCRIPTION.\n",
        "        y_arr : An array of shape N,\n",
        "            DESCRIPTION\n",
        "        per_arr : An array os shape N,1\n",
        "            DESCRIPTION.\n",
        "        task : task number we want to visualize\n",
        "        person : Subject number we want to visualize\n",
        "            DESCRIPTION. The default is None.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Just visualizes the above as a heatmap\n",
        "        None.\n",
        "        \"\"\"\n",
        "        fig,ax=plt.subplots(figsize=(12,7))\n",
        "     \n",
        "        if not (task==None):\n",
        "            task_idxs=np.argwhere(y==task).flatten()\n",
        "            print(task_idxs.shape)\n",
        "            idx_to_plot=np.random.choice(task_idxs)\n",
        "            X_to_plt=X[idx_to_plot,:,:]\n",
        "            title=\" Heat map for a specific task number \"+str(task)+\" Sub no \"+str(per_arr[idx_to_plot,0])\n",
        "        else:\n",
        "            idx_to_plot=np.random.choice(X.shape[0]).flatten()\n",
        "            X_to_plt=X[idx_to_plot,:,:]\n",
        "            title=\" Heat map for a general task number  \"+str(y[idx_to_plot])+ \" Sub no \" +str(per_arr[idx_to_plot,0])\n",
        "        plt.title(title)\n",
        "        #print(\"*\"*20)\n",
        "        print(X_to_plt.shape)    \n",
        "        sns.heatmap(X_to_plt, cmap=\"rocket\")\n",
        "        plt.xlabel(\"Time bins\")\n",
        "        plt.ylabel(\"EEG channels\")\n",
        "        plt.show()\n",
        "    def visulaize_spatial_map(self,X,y,task=1):\n",
        "        \"\"\"\n",
        "        input: input series\n",
        "        y    : output labels\n",
        "        returns gif which stores all spatial maps along the time. \n",
        "        \"\"\"\n",
        "        import cv2\n",
        "        from PIL import Image\n",
        "        task_idxs=np.argwhere(y==task).flatten()\n",
        "        print(task_idxs)\n",
        "        idx_to_plot=np.random.choice(task_idxs)\n",
        "        spatial_temporal_maps=X[idx_to_plot]\n",
        "        spatial_map_resized = cv2.resize(spatial_temporal_maps,(0,0),fx = 100,fy= 100, interpolation=cv2.INTER_AREA)\n",
        "        imgs = [Image.fromarray(img) for img in spatial_map_resized]\n",
        "        imgs[0].save(\"/content/array_images.gif\", save_all=True, append_images=imgs[1:], duration=500, loop=1)\n",
        "\n",
        "    def create_images(self, X,y):\n",
        "        \"\"\" Create the spatial images with \n",
        "            the help of spatial layout of sensors.\n",
        "            input: X datapoints\n",
        "                   y output labels\n",
        "            out  : array of datapoints as images\n",
        "\n",
        "        \"\"\"\n",
        "        import cv2\n",
        "        from PIL import Image\n",
        "        from tqdm import tqdm\n",
        "        spatial_mapping =self.get_spatial_eeg_location()    \n",
        "        X = np.array(X)\n",
        "        time = X.shape[2]\n",
        "        X_images = []\n",
        "        for idx in tqdm(range(X.shape[0])):\n",
        "          images_sequence =[]\n",
        "          for t in range(time):\n",
        "            spatial_map=np.zeros_like(spatial_mapping, dtype=np.uint8)\n",
        "            x = X[idx,:,t] ## 2115, 22, 1000\n",
        "            #print(\"x is\",x.shape)\n",
        "            for i in range(spatial_map.shape[0]):\n",
        "              for j in range(spatial_map.shape[1]):\n",
        "                if(spatial_mapping[i][j]==-1):\n",
        "                  continue\n",
        "                else:\n",
        "                  spatial_map[i,j] = ((x[spatial_mapping[i][j]]+101.0)/201.0)*255\n",
        "            images_sequence.append(spatial_map)\n",
        "          X_images.append(images_sequence)\n",
        "        return np.array(X_images)      \n",
        "            "
      ],
      "metadata": {
        "id": "0TMqbXLRfCuJ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path='/content/Dataset/project/'\n",
        "\n",
        "X_test = np.load(data_path+\"X_test.npy\")\n",
        "y_test = np.load(data_path+\"y_test.npy\")\n",
        "person_train_valid = np.load(data_path+\"person_train_valid.npy\")\n",
        "X_train_valid = np.load(data_path+\"X_train_valid.npy\")\n",
        "y_train_valid = np.load(data_path+\"y_train_valid.npy\")\n",
        "person_test = np.load(data_path+\"person_test.npy\")\n",
        "\n",
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))\n",
        "data_loader=DatasetEEG()\n",
        "\n",
        "\n",
        "\n",
        "y_train_valid_loaded=data_loader.make_labels(y_train_valid)\n",
        "y_test_loaded = data_loader.make_labels(y_test)\n",
        "X_train_valid = data_loader.create_images(X_train_valid,y_train_valid_loaded)\n",
        "X_test_images = data_loader.create_images(X_test,y_test_loaded)\n",
        "y_test_images = y_test_loaded\n",
        "\n",
        "# X_train_images = np.load('/content/gdrive/MyDrive/eeg/X_train_images.npy')\n",
        "# X_valid_images = np.load('/content/gdrive/MyDrive/eeg/X_valid_images.npy')\n",
        "# y_train_images = np.load('/content/gdrive/MyDrive/eeg/y_train_images.npy')\n",
        "# y_valid_images = np.load('/content/gdrive/MyDrive/eeg/y_valid_images.npy')\n",
        "# X_test_images = np.load('/content/gdrive/MyDrive/eeg/X_test_images.npy')\n",
        "# y_test_images = np.load('/content/gdrive/MyDrive/eeg/y_test_images.npy')\n"
      ],
      "metadata": {
        "id": "iGJ7DqB5g8hT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "d916ec78-577c-4378-ee04-7ac77218ac9e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2115/2115 [03:22<00:00, 10.45it/s]\n",
            "100%|██████████| 443/443 [00:42<00:00, 10.55it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-b0522557ed8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mX_test_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_loaded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0my_test_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mX_train_images\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mX_valid_images\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_train_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_valid_loaded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_train_valid\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# X_train_images = np.load('/content/gdrive/MyDrive/eeg/X_train_images.npy')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'DatasetEEG' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_images ,X_valid_images,  y_train_images, y_valid_images, person_train,person_valid = data_loader.train_valid_split(X_train_valid, y_train_valid_loaded, person_train_valid )\n"
      ],
      "metadata": {
        "id": "IEM7kCTOl91l"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,X,y):\n",
        "    self.X=torch.from_numpy(X).float().to(device)\n",
        "    self.y=torch.from_numpy(y).long().to(device)\n",
        "      \n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "  \n",
        "  def __getitem__(self,index):\n",
        "    return self.X[index],self.y[index]\n"
      ],
      "metadata": {
        "id": "Aj8WCKkOOoyf"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "def torch_data_loader(X_train,y_train,X_test,y_test, X_valid=[], y_valid=[],b_size=4):\n",
        "  \"\"\"\n",
        "  torch_data loader that takes X_train,y_train .... as inputs remember X's here are of shape Numtrails*channels(22)*timebins(1000)\n",
        "  we convert X to be shape of Numtrails*channels(22)*timebins(1000)*1(this dimension extra)\n",
        "\n",
        "  This returns 3 data loaders of train,test and validation if valid is not None\n",
        "  \"\"\"\n",
        "  # The procedure is to first call dataset and then dataloader in pytorch \n",
        "  dataset_train=Dataset(X_train_images,y_train_images)\n",
        "  dataloader_train=DataLoader(dataset_train,batch_size=b_size,shuffle=True)\n",
        "\n",
        "  dataset_test=Dataset(X_test_images,y_test_images)\n",
        "  dataloader_test=DataLoader(dataset_test,batch_size=b_size,shuffle=True)\n",
        "\n",
        "  if len(X_valid) ==0:\n",
        "    dataloader_valid=[]\n",
        "  else:\n",
        "    dataset_valid=Dataset(X_valid,y_valid)\n",
        "    dataloader_valid=DataLoader(dataset_valid,batch_size=b_size,shuffle=True)\n",
        "  \n",
        "  return dataloader_train,dataloader_test,dataloader_valid\n"
      ],
      "metadata": {
        "id": "yL9iT8GOtQyB"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## train epochs\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "def train_per_epoch(model,optimizer,train_loader,loss_func=nn.CrossEntropyLoss(),printevery=10,verbose=True):\n",
        "  \n",
        "  #put model in train mode\n",
        "  model.train()\n",
        "  running_loss=0\n",
        "  last_loss=0\n",
        "  # This will go through all the batches each entry in train_loader is a batch \n",
        "  for idx,data in enumerate(train_loader):\n",
        "    inputs,labels=data\n",
        "\n",
        "    #zero out gradients to avoid accumulation\n",
        "    optimizer.zero_grad();\n",
        "\n",
        "    # This will call .forward method of your model\n",
        "    op=model(inputs)\n",
        "\n",
        "    loss_val=loss_func(op,labels)\n",
        "\n",
        "    # Do  backward prop\n",
        "    loss_val.backward()\n",
        "\n",
        "    #update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # loss.item gives average loss for that batch\n",
        "    running_loss+=loss_val.item()\n",
        "\n",
        "    #last_loss is the lass fof last batch\n",
        "    last_loss=loss_val.item()\n",
        "    # Print some info for every 10 batches\n",
        "    if verbose:\n",
        "      if (idx%(printevery) == 0):\n",
        "        print('In training#####:batches completed={}/{}'.format(idx+1,len(train_loader)), 'The value of loss is {}'.format(running_loss/(printevery)))\n",
        "        running_loss=0\n",
        "\n",
        "  return model,last_loss\n",
        "\n",
        "#This module would be in model architectures .py\n",
        "#just putting model in test mode\n",
        "\n",
        "def test_model(model,data_loader,loss_func=nn.CrossEntropyLoss(),print_every=10,mode=\"train\",epoch_no=0):\n",
        "  model.eval()\n",
        "  # This is for each batch\n",
        "  total_correct=0\n",
        "  running_loss=0\n",
        "  last_loss=0\n",
        "  \n",
        "  for idx,data in enumerate(data_loader):\n",
        "    X,y=data\n",
        "    output_scores=model(X)\n",
        "    y_maxs,y_pred=torch.max(output_scores.data, 1)\n",
        "    # Converting everything to numpy arrays \n",
        "\n",
        "    y_pred_np=y_pred.cpu().detach().numpy() \n",
        "    y_actual_np=y.cpu().detach().numpy()\n",
        "\n",
        "    total_correct=total_correct+(np.where(y_pred_np==y_actual_np)[0].shape[0])\n",
        "\n",
        "    running_loss=running_loss+loss_func(output_scores,y).item()\n",
        "    last_loss=last_loss+loss_func(output_scores,y).item()\n",
        "    if idx%print_every==0:\n",
        "      # print('batches completed={}/{}'.format(idx+1,len(data_loader)), \"The value of loss \"+mode+\" is {}\".format(running_loss/(print_every)))\n",
        "      # print('batches completed={}/{}'.format(idx+1,len(data_loader)), \"The value of \"+mode+\" accuracy is {}\".format(accuracy_score(y_actual_np,y_pred_np)))\n",
        "      running_loss=0\n",
        "  \n",
        "  print('In testing######### epochs_completed={}'.format(epoch_no), \"The value of loss \"+mode+\" is {}\".format(last_loss/(idx+1)))\n",
        "  print('In testing######### epochs completed={}'.format(epoch_no), \"The value of \"+mode+\" accuracy is {}\".format(total_correct/(len(data_loader.dataset))))\n",
        "    #Returns lastloss and overall accuracy\n",
        "  return  (last_loss/(idx+1)),(total_correct/(len(data_loader.dataset)))\n",
        "  \n",
        "\n",
        "\n",
        "# This part of the code trains the model for multiple epochs \n",
        "# For each epoch we calculate the testing accuracy and loss so that we dont over fit and identify the correct num of epochs\n",
        "\n",
        "def train_multi_epochs(model,optimizer,all_data_loader,loss_func=nn.CrossEntropyLoss(),printevery=10,num_epochs=5):\n",
        "  # We have all data loaders all we do now is train our model for all the epochs and for reach epoch calculate the validation \n",
        "  #accuracy/precision, training accuracy and precision\n",
        "\n",
        "  dataloader_train,dataloader_test,dataloader_valid=all_data_loader\n",
        "  eval_metrics={}\n",
        "  eval_metrics['train_loss_hist']=[]\n",
        "  eval_metrics['train_loss_accuracy']=[]\n",
        "  eval_metrics['val_loss_hist']=[]\n",
        "  eval_metrics['test_loss_hist']=[]\n",
        "  eval_metrics['val_loss_accuracy']=[]\n",
        "  eval_metrics['test_loss_accuracy']=[]\n",
        "  max_test_accu=0\n",
        "  best_model=None\n",
        "\n",
        "  for i in range(num_epochs):\n",
        "    model,train_loss=train_per_epoch(model,optimizer,dataloader_train,loss_func,printevery)\n",
        "    \n",
        "    train_loss,train_accu=test_model(model,dataloader_train,loss_func,printevery,mode=\"train\",epoch_no=i+1)\n",
        "    eval_metrics['train_loss_hist'].append(train_loss)\n",
        "    eval_metrics['train_loss_accuracy'].append(train_accu)\n",
        "    \n",
        "    if not (len(dataloader_valid)==0):\n",
        "      val_loss,val_accu=test_model(model,dataloader_valid,loss_func,printevery,mode=\"validation\",epoch_no=i+1)\n",
        "      eval_metrics['val_loss_hist'].append(val_loss)\n",
        "      eval_metrics['val_loss_accuracy'].append(val_accu)\n",
        "  \n",
        "    test_loss,test_accu=test_model(model,dataloader_test,loss_func,printevery,mode=\"test\",epoch_no=i+1)\n",
        "    eval_metrics['test_loss_hist'].append(test_loss)\n",
        "    eval_metrics['test_loss_accuracy'].append(test_accu)\n",
        "    \n",
        "    if test_accu > max_test_accu:\n",
        "      best_model= model\n",
        "      max_test_accu=test_accu\n",
        "    print(\"Epochs done==============\",i+1,\"/\",num_epochs)\n",
        "    \n",
        "  return best_model,max_test_accu,eval_metrics\n",
        "\n",
        "\n",
        "def plot_train_test_curves(eval_metrics,save_path=''):\n",
        "  plt.figure(1)\n",
        "  plt.title(\"Loss vs num epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  x_range=np.arange(1,len(eval_metrics['test_loss_hist'])+1)\n",
        "  plt.plot(x_range,eval_metrics['train_loss_hist'], label='Train')\n",
        "  plt.plot(x_range,eval_metrics['val_loss_hist'], label='Validation')\n",
        "  plt.plot(x_range,eval_metrics['test_loss_hist'], label='Test')\n",
        "  plt.legend(loc='best')\n",
        "  if len(save_path)>0:\n",
        "    plt.savefig(save_path+'_loss.png')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(2)\n",
        "  plt.title(\"Accuracy vs num epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  x_range=np.arange(1,len(eval_metrics['test_loss_hist'])+1)\n",
        "  plt.plot(x_range,eval_metrics['train_loss_accuracy'], label='Train')\n",
        "  plt.plot(x_range,eval_metrics['val_loss_accuracy'], label='Validation')\n",
        "  plt.plot(x_range,eval_metrics['test_loss_accuracy'], label='Test')\n",
        "  plt.legend(loc='best')\n",
        "  if len(save_path)>0:\n",
        "    plt.savefig(save_path+'_accuracy.png')\n",
        "  plt.show()\n",
        "\n",
        "def save_eval_metrics(eval_metrics,save_path=''):\n",
        "  if len(save_path)>0:\n",
        "    key_list=[\"test_loss_hist\",\"train_loss_hist\",\"val_loss_hist\",\"train_loss_accuracy\",\"val_loss_accuracy\",\"test_loss_accuracy\"]\n",
        "    op=[]\n",
        "    for key in key_list:\n",
        "      op.append(eval_metrics[key])\n",
        "    pd.DataFrame(np.asarray(op).T,columns=key_list).to_csv(save_path+'.csv')\n",
        "      \n",
        "  else:\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "U7LKvv8qjHcA"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNLayer(nn.Module):\n",
        "    def __init__(self, input_channels, out_channels, kernel, stride):\n",
        "        super(CNNLayer, self).__init__()\n",
        "        self.convLayer = nn.Conv2d(input_channels, out_channels,kernel, stride=stride, padding=(1,1))\n",
        "    def forward(self,x):\n",
        "        return self.convLayer(x)\n",
        "\n",
        "class MaxPool(nn.Module):\n",
        "    def __init__(self, kernel, stride):\n",
        "        super(MaxPool, self).__init__()\n",
        "        self.maxpool = nn.MaxPool2d(kernel, stride=stride)\n",
        "    def forward(self,x):\n",
        "        return self.maxpool(x)\n",
        "class CNNPipeline(nn.Module):\n",
        "    def __init__(self, input_channels):\n",
        "        super(CNNPipeline, self).__init__()\n",
        "        self.cnn1 = CNNLayer(input_channels,16, (3,3), 1)\n",
        "        self.maxPool1 = MaxPool((2,2),2)\n",
        "        self.cnn2 = CNNLayer(16,32,(3,3),1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        #self.bn2  = nn.BatchNorm2d(32)\n",
        "        #self.bn1  = nn.BatchNorm2d(16)\n",
        "    def forward(self,x):\n",
        "        x = self.cnn1(x)\n",
        "        x = self.relu(x)\n",
        "        #x  = self.bn1(x)\n",
        "        x = self.maxPool1(x)\n",
        "        x = self.cnn2(x)\n",
        "        x = self.relu(x)\n",
        "        #x  = self.bn2(x)\n",
        "        # x = self.maxPool1(x)\n",
        "        # x = self.cnn3(x)\n",
        "        return  x\n",
        "class Linear_layer(nn.Module):\n",
        "\n",
        "    def __init__(self,hid_state=64,dropout=0.3,num_classes=4) -> None:\n",
        "        super(Linear_layer,self).__init__()\n",
        "        \n",
        "        #Fully connected net\n",
        "        self.fc_module=nn.Sequential(\n",
        "            nn.Linear(hid_state,hid_state),\n",
        "            nn.ReLU(inplace=True) ,\n",
        "            #nn.BatchNorm1d(num_features=hid_state),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(hid_state,num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self,X):\n",
        "        fc_out=self.fc_module(X)\n",
        "        return fc_out\n",
        "\n",
        "\n",
        "class CNNLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNLSTM, self).__init__()\n",
        "        self.cnnPipeline = CNNPipeline(1)\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size= 288,\n",
        "            hidden_size=64,\n",
        "            num_layers=1\n",
        "        )\n",
        "        self.fc_module = Linear_layer(64, 0.2, 4)\n",
        "        self.softmax=nn.Softmax()\n",
        "    def forward(self,x):\n",
        "        #print(x.size())\n",
        "        batch_size, timesteps, H, W = x.size()\n",
        "        cnn_in = x.view(batch_size*timesteps, 1, H, W)\n",
        "        cnn_out = self.cnnPipeline(cnn_in)\n",
        "        cnn_out = cnn_out.view(batch_size,timesteps,-1 )\n",
        "        rnn_out,_ = self.lstm(cnn_out)\n",
        "        \n",
        "        rnn_out = rnn_out[:,-1,:]\n",
        "        linear_out = self.fc_module(rnn_out)\n",
        "        return linear_out\n",
        "\n"
      ],
      "metadata": {
        "id": "Mor8XsOakOC4"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU related code if GPU is available device is GPU else it is CPU\n",
        "save_path = \"\\content\"\n",
        "import torch.optim as optim\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "b_size = 64\n",
        "dataloader_train,dataloader_test,dataloader_valid=torch_data_loader(X_train_images,y_train_images,X_test_images,y_test_images,X_valid_images,y_valid_images,b_size=b_size)\n",
        "# all_data_loader=(dataloader_train,dataloader_test,dataloader_valid)\n",
        "all_data_loader = (dataloader_train, dataloader_test,dataloader_valid)\n",
        "# all_data_loader[\"train\"] = dataloader_train\n",
        "# all_data_loader[\"test\"] = dataloader_test\n",
        "# all_data_loader[\"valid\"] = dataloader_valid\n",
        "model_cnn_lstm=CNNLSTM().to(device)\n",
        "optimizer=optim.Adam(model_cnn_lstm.parameters(),lr=1e-3)\n",
        "#optimizer=optim.SGD(params=model_cnn_lstm.parameters(),lr=1e-2,momentum=0.9)\n",
        "best_model,max_test_accu,eval_metrics = train_multi_epochs(model_cnn_lstm,optimizer,all_data_loader,num_epochs=50,printevery=1000)\n",
        "plot_train_test_curves(eval_metrics,save_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "fCHmINZYhdZc",
        "outputId": "e2f2d087-1965-42d8-84d8-7c5b4eb505e9"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In training#####:batches completed=1/27 The value of loss is 0.001382137894630432\n",
            "In testing######### epochs_completed=1 The value of loss train is 1.4369737527988575\n",
            "In testing######### epochs completed=1 The value of train accuracy is 0.24468085106382978\n",
            "In testing######### epochs_completed=1 The value of loss validation is 1.429859229496547\n",
            "In testing######### epochs completed=1 The value of validation accuracy is 0.23404255319148937\n",
            "In testing######### epochs_completed=1 The value of loss test is 1.4283061879021781\n",
            "In testing######### epochs completed=1 The value of test accuracy is 0.2866817155756208\n",
            "Epochs done============== 1 / 50\n",
            "In training#####:batches completed=1/27 The value of loss is 0.0014780811071395874\n",
            "In testing######### epochs_completed=2 The value of loss train is 1.3967471961621885\n",
            "In testing######### epochs completed=2 The value of train accuracy is 0.2553191489361702\n",
            "In testing######### epochs_completed=2 The value of loss validation is 1.3910752534866333\n",
            "In testing######### epochs completed=2 The value of validation accuracy is 0.2624113475177305\n",
            "In testing######### epochs_completed=2 The value of loss test is 1.4012871640069144\n",
            "In testing######### epochs completed=2 The value of test accuracy is 0.21670428893905191\n",
            "Epochs done============== 2 / 50\n",
            "In training#####:batches completed=1/27 The value of loss is 0.0013876056671142578\n",
            "In testing######### epochs_completed=3 The value of loss train is 1.4082205692927043\n",
            "In testing######### epochs completed=3 The value of train accuracy is 0.2553191489361702\n",
            "In testing######### epochs_completed=3 The value of loss validation is 1.4177687168121338\n",
            "In testing######### epochs completed=3 The value of validation accuracy is 0.2624113475177305\n",
            "In testing######### epochs_completed=3 The value of loss test is 1.4117498397827148\n",
            "In testing######### epochs completed=3 The value of test accuracy is 0.21670428893905191\n",
            "Epochs done============== 3 / 50\n",
            "In training#####:batches completed=1/27 The value of loss is 0.0014284071922302246\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-1836814af40e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cnn_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#optimizer=optim.SGD(params=model_cnn_lstm.parameters(),lr=1e-2,momentum=0.9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_test_accu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_multi_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cnn_lstm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprintevery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mplot_train_test_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-6258ff1ef246>\u001b[0m in \u001b[0;36mtrain_multi_epochs\u001b[0;34m(model, optimizer, all_data_loader, loss_func, printevery, num_epochs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_per_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprintevery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_accu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprintevery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-6258ff1ef246>\u001b[0m in \u001b[0;36mtrain_per_epoch\u001b[0;34m(model, optimizer, train_loader, loss_func, printevery, verbose)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# loss.item gives average loss for that batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mrunning_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#last_loss is the lass fof last batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_images[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkNL4KiDD0pe",
        "outputId": "15c4380c-2213-45d5-9fde-37a1fc544ee0"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[140, 140, 135, 135, 135, 134, 134],\n",
              "       [140, 137, 137, 137, 132, 132, 134],\n",
              "       [132, 135, 132, 132, 126, 124, 121],\n",
              "       [130, 130, 128, 125, 123, 121, 121],\n",
              "       [130, 124, 124, 122, 120, 120, 121],\n",
              "       [124, 124, 119, 119, 119, 120, 120]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZijis5Cmgd5",
        "outputId": "ddf0f43f-313b-4e6e-8e96-309ce5e92d48"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[140 140 135 ... 135 134 134]\n",
            "   [140 137 137 ... 132 132 134]\n",
            "   [132 135 132 ... 126 124 121]\n",
            "   [130 130 128 ... 123 121 121]\n",
            "   [130 124 124 ... 120 120 121]\n",
            "   [124 124 119 ... 119 120 120]]\n",
            "\n",
            "  [[134 134 130 ... 130 128 128]\n",
            "   [134 133 133 ... 127 127 128]\n",
            "   [130 130 128 ... 122 121 117]\n",
            "   [128 128 124 ... 119 118 118]\n",
            "   [128 119 119 ... 116 116 118]\n",
            "   [119 119 114 ... 114 116 116]]\n",
            "\n",
            "  [[130 130 126 ... 126 123 123]\n",
            "   [130 129 129 ... 125 125 123]\n",
            "   [127 127 124 ... 120 118 114]\n",
            "   [124 124 119 ... 115 115 115]\n",
            "   [124 114 114 ... 112 112 115]\n",
            "   [114 114 109 ... 109 112 112]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[118 118 115 ... 115 125 125]\n",
            "   [118 116 116 ... 121 121 125]\n",
            "   [125 122 125 ... 129 131 131]\n",
            "   [129 129 132 ... 138 138 138]\n",
            "   [129 139 139 ... 144 144 138]\n",
            "   [139 139 147 ... 147 144 144]]\n",
            "\n",
            "  [[118 118 117 ... 117 124 124]\n",
            "   [118 118 118 ... 121 121 124]\n",
            "   [126 121 125 ... 129 130 131]\n",
            "   [128 128 133 ... 138 137 137]\n",
            "   [128 140 140 ... 142 142 137]\n",
            "   [140 140 143 ... 143 142 142]]\n",
            "\n",
            "  [[123 123 117 ... 117 125 125]\n",
            "   [123 118 118 ... 121 121 125]\n",
            "   [129 127 126 ... 128 131 129]\n",
            "   [133 133 133 ... 137 136 136]\n",
            "   [133 141 141 ... 141 141 136]\n",
            "   [141 141 140 ... 140 141 141]]]\n",
            "\n",
            "\n",
            " [[[141 141 139 ... 139 125 125]\n",
            "   [141 138 138 ... 128 128 125]\n",
            "   [129 133 130 ... 120 116 114]\n",
            "   [121 121 121 ... 117 113 113]\n",
            "   [121 115 115 ... 112 112 113]\n",
            "   [115 115 107 ... 107 112 112]]\n",
            "\n",
            "  [[145 145 148 ... 148 128 128]\n",
            "   [145 146 146 ... 136 136 128]\n",
            "   [131 134 137 ... 128 120 118]\n",
            "   [121 121 127 ... 120 116 116]\n",
            "   [121 118 118 ... 115 115 116]\n",
            "   [118 118 110 ... 110 115 115]]\n",
            "\n",
            "  [[145 145 150 ... 150 130 130]\n",
            "   [145 149 149 ... 139 139 130]\n",
            "   [129 132 138 ... 129 120 116]\n",
            "   [120 120 126 ... 121 115 115]\n",
            "   [120 117 117 ... 115 115 115]\n",
            "   [117 117 112 ... 112 115 115]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[123 123 122 ... 122 121 121]\n",
            "   [123 121 121 ... 120 120 121]\n",
            "   [123 121 122 ... 121 120 120]\n",
            "   [124 124 121 ... 120 120 120]\n",
            "   [124 120 120 ... 119 119 120]\n",
            "   [120 120 120 ... 120 119 119]]\n",
            "\n",
            "  [[121 121 124 ... 124 124 124]\n",
            "   [121 122 122 ... 125 125 124]\n",
            "   [122 121 124 ... 126 124 123]\n",
            "   [124 124 125 ... 125 125 125]\n",
            "   [124 125 125 ... 126 126 125]\n",
            "   [125 125 125 ... 125 126 126]]\n",
            "\n",
            "  [[122 122 126 ... 126 128 128]\n",
            "   [122 124 124 ... 129 129 128]\n",
            "   [123 120 126 ... 129 128 126]\n",
            "   [123 123 126 ... 125 126 126]\n",
            "   [123 125 125 ... 125 125 126]\n",
            "   [125 125 125 ... 125 125 125]]]\n",
            "\n",
            "\n",
            " [[[122 122 114 ... 114 106 106]\n",
            "   [122 116 116 ... 106 106 106]\n",
            "   [122 123 117 ... 105 105 111]\n",
            "   [121 121 115 ... 108 107 107]\n",
            "   [121 115 115 ... 113 113 107]\n",
            "   [115 115 119 ... 119 113 113]]\n",
            "\n",
            "  [[125 125 117 ... 117 109 109]\n",
            "   [125 119 119 ... 108 108 109]\n",
            "   [122 126 122 ... 108 109 109]\n",
            "   [124 124 118 ... 109 107 107]\n",
            "   [124 117 117 ... 115 115 107]\n",
            "   [117 117 119 ... 119 115 115]]\n",
            "\n",
            "  [[128 128 120 ... 120 114 114]\n",
            "   [128 123 123 ... 115 115 114]\n",
            "   [133 129 126 ... 114 111 116]\n",
            "   [127 127 124 ... 114 112 112]\n",
            "   [127 121 121 ... 116 116 112]\n",
            "   [121 121 119 ... 119 116 116]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[117 117 118 ... 118 120 120]\n",
            "   [117 120 120 ... 122 122 120]\n",
            "   [131 126 126 ... 125 125 134]\n",
            "   [130 130 130 ... 125 126 126]\n",
            "   [130 129 129 ... 126 126 126]\n",
            "   [129 129 126 ... 126 126 126]]\n",
            "\n",
            "  [[112 112 107 ... 107 114 114]\n",
            "   [112 109 109 ... 109 109 114]\n",
            "   [125 120 115 ... 112 115 118]\n",
            "   [126 126 119 ... 114 115 115]\n",
            "   [126 121 121 ... 117 117 115]\n",
            "   [121 121 122 ... 122 117 117]]\n",
            "\n",
            "  [[116 116 112 ... 112 115 115]\n",
            "   [116 113 113 ... 112 112 115]\n",
            "   [123 121 117 ... 113 114 119]\n",
            "   [124 124 118 ... 115 114 114]\n",
            "   [124 119 119 ... 116 116 114]\n",
            "   [119 119 120 ... 120 116 116]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[126 126 141 ... 141 131 131]\n",
            "   [126 131 131 ... 133 133 131]\n",
            "   [109 101 111 ... 120 121 124]\n",
            "   [ 75  75  88 ... 104 111 111]\n",
            "   [ 75  76  76 ...  91  91 111]\n",
            "   [ 76  76  76 ...  76  91  91]]\n",
            "\n",
            "  [[121 121 132 ... 132 128 128]\n",
            "   [121 123 123 ... 127 127 128]\n",
            "   [111 103 106 ... 113 118 119]\n",
            "   [ 80  80  85 ...  97 101 101]\n",
            "   [ 80  71  71 ...  84  84 101]\n",
            "   [ 71  71  71 ...  71  84  84]]\n",
            "\n",
            "  [[130 130 131 ... 131 128 128]\n",
            "   [130 124 124 ... 127 127 128]\n",
            "   [124 116 111 ... 113 117 113]\n",
            "   [ 95  95  92 ...  99 102 102]\n",
            "   [ 95  79  79 ...  88  88 102]\n",
            "   [ 79  79  79 ...  79  88  88]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[122 122 133 ... 133 129 129]\n",
            "   [122 129 129 ... 131 131 129]\n",
            "   [114 123 133 ... 137 134 129]\n",
            "   [127 127 138 ... 142 135 135]\n",
            "   [127 141 141 ... 146 146 135]\n",
            "   [141 141 145 ... 145 146 146]]\n",
            "\n",
            "  [[127 127 136 ... 136 133 133]\n",
            "   [127 132 132 ... 133 133 133]\n",
            "   [115 127 134 ... 137 135 129]\n",
            "   [129 129 138 ... 142 136 136]\n",
            "   [129 142 142 ... 146 146 136]\n",
            "   [142 142 146 ... 146 146 146]]\n",
            "\n",
            "  [[130 130 135 ... 135 134 134]\n",
            "   [130 131 131 ... 130 130 134]\n",
            "   [118 127 132 ... 131 131 128]\n",
            "   [124 124 132 ... 139 135 135]\n",
            "   [124 139 139 ... 141 141 135]\n",
            "   [139 139 140 ... 140 141 141]]]\n",
            "\n",
            "\n",
            " [[[ 98  98 104 ... 104 116 116]\n",
            "   [ 98 107 107 ... 112 112 116]\n",
            "   [ 96 101 109 ... 121 124 137]\n",
            "   [114 114 121 ... 129 133 133]\n",
            "   [114 138 138 ... 144 144 133]\n",
            "   [138 138 152 ... 152 144 144]]\n",
            "\n",
            "  [[113 113 113 ... 113 112 112]\n",
            "   [113 118 118 ... 115 115 112]\n",
            "   [123 116 122 ... 124 122 128]\n",
            "   [126 126 129 ... 132 133 133]\n",
            "   [126 139 139 ... 144 144 133]\n",
            "   [139 139 152 ... 152 144 144]]\n",
            "\n",
            "  [[156 156 144 ... 144 154 154]\n",
            "   [156 154 154 ... 152 152 154]\n",
            "   [150 155 157 ... 159 161 162]\n",
            "   [161 161 161 ... 163 162 162]\n",
            "   [161 166 166 ... 171 171 162]\n",
            "   [166 166 176 ... 176 171 171]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[149 149 130 ... 130 153 153]\n",
            "   [149 145 145 ... 146 146 153]\n",
            "   [164 151 145 ... 150 164 172]\n",
            "   [151 151 143 ... 151 163 163]\n",
            "   [151 143 143 ... 154 154 163]\n",
            "   [143 143 145 ... 145 154 154]]\n",
            "\n",
            "  [[122 122 114 ... 114 125 125]\n",
            "   [122 126 126 ... 128 128 125]\n",
            "   [128 126 126 ... 130 134 134]\n",
            "   [135 135 128 ... 132 142 142]\n",
            "   [135 133 133 ... 139 139 142]\n",
            "   [133 133 136 ... 136 139 139]]\n",
            "\n",
            "  [[116 116  97 ...  97 114 114]\n",
            "   [116 110 110 ... 108 108 114]\n",
            "   [124 121 112 ... 111 121 125]\n",
            "   [132 132 118 ... 117 126 126]\n",
            "   [132 131 131 ... 128 128 126]\n",
            "   [131 131 136 ... 136 128 128]]]\n",
            "\n",
            "\n",
            " [[[134 134 132 ... 132 142 142]\n",
            "   [134 135 135 ... 138 138 142]\n",
            "   [134 139 141 ... 136 131 139]\n",
            "   [142 142 144 ... 139 132 132]\n",
            "   [142 151 151 ... 147 147 132]\n",
            "   [151 151 157 ... 157 147 147]]\n",
            "\n",
            "  [[134 134 127 ... 127 134 134]\n",
            "   [134 132 132 ... 133 133 134]\n",
            "   [134 140 139 ... 131 122 126]\n",
            "   [142 142 141 ... 130 120 120]\n",
            "   [142 142 142 ... 138 138 120]\n",
            "   [142 142 148 ... 148 138 138]]\n",
            "\n",
            "  [[138 138 135 ... 135 132 132]\n",
            "   [138 138 138 ... 137 137 132]\n",
            "   [142 142 144 ... 136 121 128]\n",
            "   [143 143 145 ... 134 123 123]\n",
            "   [143 145 145 ... 139 139 123]\n",
            "   [145 145 149 ... 149 139 139]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[119 119 120 ... 120 115 115]\n",
            "   [119 119 119 ... 115 115 115]\n",
            "   [111 112 117 ... 113 112 112]\n",
            "   [110 110 114 ... 113 108 108]\n",
            "   [110 110 110 ... 113 113 108]\n",
            "   [110 110 106 ... 106 113 113]]\n",
            "\n",
            "  [[123 123 124 ... 124 114 114]\n",
            "   [123 123 123 ... 118 118 114]\n",
            "   [116 115 119 ... 118 114 115]\n",
            "   [111 111 116 ... 118 114 114]\n",
            "   [111 116 116 ... 120 120 114]\n",
            "   [116 116 113 ... 113 120 120]]\n",
            "\n",
            "  [[124 124 121 ... 121 112 112]\n",
            "   [124 121 121 ... 114 114 112]\n",
            "   [119 116 117 ... 116 115 110]\n",
            "   [111 111 116 ... 121 117 117]\n",
            "   [111 120 120 ... 123 123 117]\n",
            "   [120 120 120 ... 120 123 123]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUMQZKh3nTsj",
        "outputId": "efcd1655-c2d3-4c8e-c43f-451396c91aeb"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[  3.27148438,  10.05859375,   1.12304688, ...,   3.75976562,\n",
              "          -0.43945312,   5.6640625 ],\n",
              "        [  0.73242188,   4.8828125 ,   1.12304688, ...,  -0.1953125 ,\n",
              "          -3.85742188,   1.51367188],\n",
              "        [  3.95507812,   9.91210938,   1.22070312, ...,   1.31835938,\n",
              "          -2.78320312,   3.41796875],\n",
              "        ...,\n",
              "        [  9.81445312,   9.52148438,   0.04882812, ...,   4.1015625 ,\n",
              "          -3.17382812,   3.22265625],\n",
              "        [  8.54492188,   9.61914062,   0.87890625, ...,   6.59179688,\n",
              "          -0.92773438,   4.83398438],\n",
              "        [ 12.59765625,  10.88867188,  -0.63476562, ...,   5.12695312,\n",
              "          -4.05273438,   2.9296875 ]],\n",
              "\n",
              "       [[-27.34375   , -28.66210938, -24.56054688, ...,  -5.41992188,\n",
              "          -4.58984375, -11.27929688],\n",
              "        [-21.19140625, -21.53320312, -19.38476562, ...,  -8.83789062,\n",
              "          -6.88476562, -15.8203125 ],\n",
              "        [-26.22070312, -30.078125  , -26.953125  , ...,  -7.71484375,\n",
              "          -5.90820312, -12.45117188],\n",
              "        ...,\n",
              "        [-16.94335938, -15.8203125 , -14.84375   , ...,  -5.12695312,\n",
              "          -3.56445312,  -6.10351562],\n",
              "        [-14.16015625, -13.0859375 , -12.93945312, ...,  -5.17578125,\n",
              "          -2.88085938,  -5.56640625],\n",
              "        [-10.00976562, -10.30273438, -10.20507812, ...,  -3.66210938,\n",
              "          -1.46484375,  -4.05273438]],\n",
              "\n",
              "       [[ -5.859375  , -12.35351562,  -4.34570312, ...,  12.06054688,\n",
              "          12.93945312,  13.8671875 ],\n",
              "        [ -2.49023438,  -8.69140625,   0.34179688, ...,   2.88085938,\n",
              "           6.98242188,   5.76171875],\n",
              "        [ -1.46484375,  -8.7890625 ,   0.24414062, ...,   6.00585938,\n",
              "           6.54296875,   7.71484375],\n",
              "        ...,\n",
              "        [  4.296875  ,  -2.5390625 ,   3.61328125, ...,  -7.51953125,\n",
              "          -5.12695312,  -8.203125  ],\n",
              "        [  6.29882812,  -0.83007812,   4.19921875, ...,  -4.4921875 ,\n",
              "          -2.83203125,  -6.39648438],\n",
              "        [  3.41796875,  -2.97851562,   3.61328125, ..., -10.98632812,\n",
              "          -9.22851562, -12.74414062]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-12.40234375, -10.05859375,  -8.05664062, ...,  16.89453125,\n",
              "           9.32617188,   5.22460938],\n",
              "        [-10.49804688, -13.23242188,  -7.95898438, ...,   3.41796875,\n",
              "          -2.734375  ,  -5.859375  ],\n",
              "        [-11.27929688,  -9.42382812,  -5.46875   , ...,   0.73242188,\n",
              "          -6.93359375, -12.15820312],\n",
              "        ...,\n",
              "        [-12.74414062, -15.234375  ,  -9.9609375 , ...,   2.39257812,\n",
              "         -12.45117188, -19.82421875],\n",
              "        [-13.671875  , -15.28320312, -11.23046875, ...,   4.83398438,\n",
              "          -8.64257812, -14.40429688],\n",
              "        [-10.05859375, -12.64648438, -10.10742188, ...,   5.51757812,\n",
              "          -7.27539062, -13.52539062]],\n",
              "\n",
              "       [[ -4.73632812,  -4.44335938,  -4.24804688, ...,  16.30859375,\n",
              "          16.30859375,  15.38085938],\n",
              "        [  6.20117188,   6.78710938,  11.71875   , ...,   8.30078125,\n",
              "          13.8671875 ,  13.0859375 ],\n",
              "        [  6.59179688,   7.12890625,   9.47265625, ...,  12.6953125 ,\n",
              "          18.50585938,  17.08984375],\n",
              "        ...,\n",
              "        [  6.54296875,   8.74023438,   9.9609375 , ...,  10.3515625 ,\n",
              "          17.04101562,  19.3359375 ],\n",
              "        [  0.83007812,   1.61132812,   3.22265625, ...,  10.44921875,\n",
              "          15.8203125 ,  16.6015625 ],\n",
              "        [  0.83007812,   3.90625   ,   6.49414062, ...,  17.578125  ,\n",
              "          20.703125  ,  22.41210938]],\n",
              "\n",
              "       [[ -0.24414062,   1.31835938,   2.734375  , ...,   1.70898438,\n",
              "          -4.05273438,  -1.46484375],\n",
              "        [  2.5390625 ,   2.44140625,   2.5390625 , ...,   4.34570312,\n",
              "           0.43945312,   0.5859375 ],\n",
              "        [  0.92773438,   3.46679688,   4.24804688, ...,   5.859375  ,\n",
              "           1.12304688,   3.61328125],\n",
              "        ...,\n",
              "        [  5.37109375,   6.10351562,   7.08007812, ...,  20.16601562,\n",
              "          20.84960938,  25.        ],\n",
              "        [  3.46679688,   3.46679688,   4.44335938, ...,  20.36132812,\n",
              "          20.99609375,  24.36523438],\n",
              "        [  8.3984375 ,   8.05664062,   8.10546875, ...,  24.90234375,\n",
              "          25.73242188,  30.95703125]]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xrcsn-9wni8S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}